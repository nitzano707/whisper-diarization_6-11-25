import os
import runpod
import requests
import tempfile
import whisperx
import torch
import gc

device = "cuda" if torch.cuda.is_available() else "cpu"
compute_type = "float16" if device == "cuda" else "int8"

print(f"ğŸ–¥ï¸  Device: {device}")

def handler(event):
    try:
        input_data = event.get("input", {})
        file_url = input_data.get("file_url")
        language = input_data.get("language", "he")
        do_diarize = input_data.get("diarize", True)
        
        if not file_url:
            return {"error": "file_url required"}
        
        print(f"ğŸ“¥ Downloading: {file_url}")
        
        # ×”×•×¨×“×”
        with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as tmp:
            response = requests.get(file_url, timeout=300)
            response.raise_for_status()
            tmp.write(response.content)
            tmp.flush()
            audio_path = tmp.name
        
        print(f"âœ… Downloaded: {os.path.getsize(audio_path)} bytes")
        
        # ×ª××œ×•×œ
        print("ğŸ™ï¸  Transcribing...")
        model = whisperx.load_model("base", device, compute_type=compute_type, language=language)
        audio = whisperx.load_audio(audio_path)
        result = model.transcribe(audio, batch_size=16)
        
        transcription = " ".join([seg["text"] for seg in result["segments"]])
        print(f"âœ… Transcribed: {len(transcription)} chars")
        
        # ×©×—×¨×•×¨ ×–×™×›×¨×•×Ÿ
        del model
        gc.collect()
        torch.cuda.empty_cache() if device == "cuda" else None
        
        speakers = []
        
        # ×“×™××¨×™×–×¦×™×”
        if do_diarize:
            HF_TOKEN = os.getenv("HF_TOKEN")
            if HF_TOKEN:
                try:
                    print("ğŸ” Aligning...")
                    model_a, metadata = whisperx.load_align_model(
                        language_code=language, 
                        device=device
                    )
                    result = whisperx.align(
                        result["segments"], 
                        model_a, 
                        metadata, 
                        audio, 
                        device
                    )
                    
                    # ×©×—×¨×•×¨ ×–×™×›×¨×•×Ÿ
                    del model_a
                    gc.collect()
                    torch.cuda.empty_cache() if device == "cuda" else None
                    
                    print("ğŸ‘¥ Diarizing...")
                    diarize_model = whisperx.DiarizationPipeline(
                        use_auth_token=HF_TOKEN, 
                        device=device
                    )
                    diarize_segments = diarize_model(audio)
                    result = whisperx.assign_word_speakers(diarize_segments, result)
                    
                    for seg in result["segments"]:
                        speakers.append({
                            "speaker": seg.get("speaker", "UNKNOWN"),
                            "start": round(seg["start"], 2),
                            "end": round(seg["end"], 2),
                            "text": seg["text"].strip()
                        })
                    
                    print(f"âœ… Found {len(set([s['speaker'] for s in speakers]))} speakers")
                    
                except Exception as e:
                    print(f"âš ï¸  Diarization failed: {e}")
        
        # × ×™×§×•×™
        try:
            os.unlink(audio_path)
        except:
            pass
        
        return {
            "transcription": transcription,
            "speakers": speakers,
            "language": language,
            "status": "success"
        }
        
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        print(f"âŒ Error:\n{error_details}")
        return {
            "error": str(e),
            "status": "error"
        }

if __name__ == "__main__":
    print("ğŸš€ WhisperX Worker Starting")
    runpod.serverless.start({"handler": handler})
```

---

## âš™ï¸ **×”×’×“×¨×•×ª Runpod - ×—×©×•×‘ ×××•×“!**

×‘×¢×ª ×™×¦×™×¨×ª Endpoint, ×”×’×“×¨:
```
Container Disk: 20 GB
GPU: RTX 4090 ××• A40
Execution Timeout: 300 (5 ×“×§×•×ª)
Max Workers: 3
Min Workers: 0
